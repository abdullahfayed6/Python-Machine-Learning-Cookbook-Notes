{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["coRjeDnfHQ_R","WYWHUvAIIhYl","h0NNrBs5Ki6F","hgfwZokCMB6w","RNrMxwxoX6n4"],"authorship_tag":"ABX9TyPYJH4vy8Wwzn7lURVOZpMK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression , LogisticRegressionCV\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np"],"metadata":{"id":"4rO5IZtTHT-M","executionInfo":{"status":"ok","timestamp":1754433312369,"user_tz":-180,"elapsed":6,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# **Training a Binary Classifier**"],"metadata":{"id":"coRjeDnfHQ_R"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"Nwo4kTdGGVQj","executionInfo":{"status":"ok","timestamp":1754433191714,"user_tz":-180,"elapsed":17,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"outputs":[],"source":["# Load data with only two classes\n","iris = datasets.load_iris()\n","features = iris.data[:100,:]\n","target = iris.target[:100]"]},{"cell_type":"code","source":["scaler = StandardScaler()\n","features_standardized = scaler.fit_transform(features)"],"metadata":{"id":"YXi052f6HWvr","executionInfo":{"status":"ok","timestamp":1754433191715,"user_tz":-180,"elapsed":7,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create lr  object and fit\n","lr = LogisticRegression()\n","model = lr.fit(features_standardized, target)"],"metadata":{"id":"X6cJA0H0Hctw","executionInfo":{"status":"ok","timestamp":1754433191732,"user_tz":-180,"elapsed":21,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**Logistic Regression – Discussion**\n","\n","Despite having **\"regression\"** in its name, **logistic regression** is actually a widely used **binary classifier** — meaning the target variable $y$ can only take two values: 0 or 1.\n","\n","In logistic regression, a linear model like:\n","\n","$$\n","z = \\beta_0 + \\beta_1 x\n","$$\n","\n","is passed through a **logistic (sigmoid) function**:\n","\n","$$\n","\\sigma(z) = \\frac{1}{1 + e^{-z}}\n","$$\n","\n","Thus, the probability that the $i$-th observation belongs to class 1 is:\n","\n","$$\n","P(y_i = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\n","$$\n","\n","Where:\n","\n","* $P(y_i = 1 \\mid X)$: probability that $y_i = 1$, given data $X$\n","* $\\beta_0, \\beta_1$: parameters learned during training\n","* $e$: Euler's number (\\~2.718)\n","* $x$: input feature(s)\n","\n"],"metadata":{"id":"NiyZAE4wIDbH"}},{"cell_type":"code","source":["# Create new observation\n","new_observation = [[.5, .5, .5, .5]]\n","\n","# Predict class\n","model.predict(new_observation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSezZOwjHi5t","executionInfo":{"status":"ok","timestamp":1754433191748,"user_tz":-180,"elapsed":6,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}},"outputId":"53fa385f-731e-46d9-cbe4-34114e8a9d75"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["\n","The **logistic function** constrains the output to the range $[0, 1]$, so it can be interpreted as a probability.\n","\n","**Classification Rule**\n","\n","* If $P(y_i = 1 \\mid X) > 0.5$, predict **class 1**\n","* Otherwise, predict **class 0**"],"metadata":{"id":"AITqvnvqIb_k"}},{"cell_type":"code","source":["# View predicted probabilities\n","model.predict_proba(new_observation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvpG_1UiHoN3","executionInfo":{"status":"ok","timestamp":1754433191764,"user_tz":-180,"elapsed":5,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}},"outputId":"f091de62-bc62-4b1d-9005-63afb7393627"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.17740549, 0.82259451]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# **Training a Multiclass Classifier**"],"metadata":{"id":"WYWHUvAIIhYl"}},{"cell_type":"code","source":["# Load data\n","iris = datasets.load_iris()\n","features = iris.data\n","target = iris.target"],"metadata":{"id":"CVL-dsEOHq68","executionInfo":{"status":"ok","timestamp":1754433191783,"user_tz":-180,"elapsed":7,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Standardize features\n","scaler = StandardScaler()\n","features_standardized = scaler.fit_transform(features)"],"metadata":{"id":"6ftN85F1ItyT","executionInfo":{"status":"ok","timestamp":1754433191852,"user_tz":-180,"elapsed":16,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**Logistic Regression for Multiclass Classification**\n","\n","By default, **logistic regression** is a **binary classifier**, meaning it can only distinguish between two classes.\n","\n","However, two clever extensions allow it to handle **multiclass classification** problems:\n","\n","---\n","\n","**One-vs-Rest Logistic Regression (OvR)**\n","\n","* Trains **one binary classifier per class**.\n","* For each classifier, it tries to distinguish:\n","  **“Is this observation class $k$? Yes or No?”**\n","\n","The model then selects the class with the **highest probability**.\n","\n","---\n","\n","**Multinomial Logistic Regression (MLR)**\n","\n","Instead of multiple independent classifiers, **a single model** is trained using the **softmax function**, which generalizes the sigmoid for multiclass:\n","\n","$$\n","P(y_i = k \\mid X) = \\frac{e^{\\beta_k \\cdot x_i}}{\\sum_{j=1}^{K} e^{\\beta_j \\cdot x_i}}\n","$$\n","\n","Where:\n","\n","* $P(y_i = k \\mid X)$: Probability that the $i$-th sample is of class $k$\n","* $K$: Total number of classes\n","* $\\beta_k$: Parameters for class $k$\n","* $x_i$: Feature vector for the $i$-th observation\n","* $e$: Euler's number\n"],"metadata":{"id":"6f2PybHIJdcd"}},{"cell_type":"code","source":["# Create one-vs-rest logistic regression object\n","logistic_regression = LogisticRegression(random_state=0, multi_class=\"multinomial\")\n","\n","# Train model\n","model = logistic_regression.fit(features_standardized, target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JL63QG4nIvCk","executionInfo":{"status":"ok","timestamp":1754433192058,"user_tz":-180,"elapsed":211,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}},"outputId":"420bb88f-4183-4181-9716-5fc810d41f8d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["new_observation = [[.5, .5, .5, .5]]\n","\n","model.predict(new_observation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c72sGCSyIw40","executionInfo":{"status":"ok","timestamp":1754433192065,"user_tz":-180,"elapsed":6,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}},"outputId":"c1aae852-36b4-4cad-ebab-1f96e664d978"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model.predict_proba(new_observation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TM5Hwi2tKRog","executionInfo":{"status":"ok","timestamp":1754433192118,"user_tz":-180,"elapsed":52,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}},"outputId":"4eb63b98-0158-4e0b-feb7-3f1497c5330d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.0198333 , 0.74472208, 0.23544462]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# **Reducing Variance Through Regularization**"],"metadata":{"id":"h0NNrBs5Ki6F"}},{"cell_type":"markdown","source":["Tune the regularization strength hyperparameter, C"],"metadata":{"id":"2AwnrR1fK8LO"}},{"cell_type":"code","source":["# Load data\n","iris = datasets.load_iris()\n","features = iris.data\n","target = iris.target"],"metadata":{"id":"_6HhXz3rKatI","executionInfo":{"status":"ok","timestamp":1754433192137,"user_tz":-180,"elapsed":17,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Standardize features\n","scaler = StandardScaler()\n","features_standardized = scaler.fit_transform(features)"],"metadata":{"id":"VlaVvnKzK-JZ","executionInfo":{"status":"ok","timestamp":1754433192138,"user_tz":-180,"elapsed":16,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Regularization Strength\n","\n","* $\\alpha$: Controls how strong the penalty is\n","* In **scikit-learn**, we use:\n","\n","$$\n","C = \\frac{1}{\\alpha}\n","$$\n","\n","So:\n","\n","* **Larger $C$** = **weaker** regularization (more flexible model)\n","* **Smaller $C$** = **stronger** regularization (more constrained model)\n"],"metadata":{"id":"TT5_BQCiL3fR"}},{"cell_type":"code","source":["# Create decision tree classifier object\n","logistic_regression = LogisticRegressionCV(\n","    penalty='l2', Cs=10, random_state=0, n_jobs=-1)\n","\n","# Train model\n","model = logistic_regression.fit(features_standardized, target)"],"metadata":{"id":"5MxmHly9K_IU","executionInfo":{"status":"ok","timestamp":1754433196772,"user_tz":-180,"elapsed":4639,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **Training a Classifier on Very Large Data**"],"metadata":{"id":"hgfwZokCMB6w"}},{"cell_type":"markdown","source":["using average gradient (SAG) solver"],"metadata":{"id":"6ySCG66iXYgg"}},{"cell_type":"code","source":["# Load data\n","iris = datasets.load_iris()\n","features = iris.data\n","target = iris.target"],"metadata":{"id":"Bs558mPZMDuI","executionInfo":{"status":"ok","timestamp":1754433196838,"user_tz":-180,"elapsed":67,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Standardize features\n","scaler = StandardScaler()\n","features_standardized = scaler.fit_transform(features)"],"metadata":{"id":"itupoXNbXcCI","executionInfo":{"status":"ok","timestamp":1754433202580,"user_tz":-180,"elapsed":13,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Create logistic regression object\n","logistic_regression = LogisticRegression(random_state=0, solver=\"sag\")\n","\n","# Train model\n","model = logistic_regression.fit(features_standardized, target)"],"metadata":{"id":"cDkV8QoxXiiY","executionInfo":{"status":"ok","timestamp":1754433215584,"user_tz":-180,"elapsed":59,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["When to Use `solver='sag'`?\n","\n","* Your dataset has **tens or hundreds of thousands** of samples\n","* You want **efficient training**\n","* You're using **L2 regularization** (`penalty='l2'`)\n","* You're OK with using **only binary or multiclass** classification (not multinomial with L1)\n","\n"],"metadata":{"id":"AGCeHByMXv_a"}},{"cell_type":"markdown","source":["# **Handling Imbalanced Classes**"],"metadata":{"id":"RNrMxwxoX6n4"}},{"cell_type":"code","source":["iris = datasets.load_iris()\n","features = iris.data\n","target = iris.target\n","\n","features = features[40:,:]\n","target = target[40:]\n","\n","target = np.where((target == 0), 0, 1)"],"metadata":{"id":"tL_f4GcRXkNu","executionInfo":{"status":"ok","timestamp":1754433340310,"user_tz":-180,"elapsed":26,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Standardize features\n","scaler = StandardScaler()\n","features_standardized = scaler.fit_transform(features)"],"metadata":{"id":"5uVg_4CAX-vX","executionInfo":{"status":"ok","timestamp":1754433345473,"user_tz":-180,"elapsed":15,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Create decision tree classifier object\n","logistic_regression = LogisticRegression(random_state=0, class_weight=\"balanced\")\n","\n","# Train model\n","model = logistic_regression.fit(features_standardized, target)"],"metadata":{"id":"GLVdjV4cYFao","executionInfo":{"status":"ok","timestamp":1754433351771,"user_tz":-180,"elapsed":53,"user":{"displayName":"Abdullah Fayed","userId":"07741069294113967274"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["When using `class_weight=\"balanced\"`, scikit-learn computes the weight for class $j$ as:\n","\n","$$\n","w_j = \\frac{n}{k \\cdot n_j}\n","$$\n","\n","Where:\n","\n","* $w_j$: Weight assigned to class $j$\n","* $n$: Total number of observations\n","* $n_j$: Number of observations in class $j$\n","* $k$: Total number of classes\n","\n","So, **rare classes get higher weights**, making the model pay more attention to them during training.\n"],"metadata":{"id":"uvANOJdTYQ8I"}},{"cell_type":"code","source":[],"metadata":{"id":"Q61WSpPIYG8J"},"execution_count":null,"outputs":[]}]}